{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Script to evaluate the output of the mappings between two lists of person names**\n",
    "\n",
    "This notebook contains the steps for evaluating how precise the mappings between two lists of person names (ListA and ListB) were (when using the mapping notebook \"MappingPersonNames.ipynb\".\n",
    "\n",
    "It needs as an input the correct mapped Ids between two lists.\n",
    "\n",
    "This script is written by Liliana Melgar-Estrada for the SKILLNET PROJECT (https://skillnet.nl/)\n",
    "\n",
    "Last update: June 21, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation (externally, before importing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the mappings between two lists have been evaluated and confirmed by an export, create a file that contains the mapped Ids. Besides, import the original lists of names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "# import jellyfish\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import csv\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "# pd.options.display.max_columns = 10\n",
    "pd.options.display.max_rows = 1000\n",
    "# pd.options.display.width = 1000\n",
    "\n",
    "# to add timestamp to file names\n",
    "import time\n",
    "\n",
    "# for progress bar (https://datascientyst.com/progress-bars-pandas-python-tqdm/)\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data is located in the repository folder indicated in the path here\n",
    "# this is the local path to the raw data in your own computer to where you downloaded/cloned the repository\n",
    "pathRawDataFolder = f'/Users/Melga001/stack/workspace/SKILLNET-PRODUCTION/_sharedRepositoriesGithub/mappingPersonNames/data/raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ListA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test version, ListA contains unique names from the Catalogus Epistolarum Neerlandicarum (CEN) extracted from a slice of correspondents from van Leeuwenhoek and Swammerdam (internal note: cy08)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here the first file (ListA), this is the names you want to map the other list to.\n",
    "# the list is imported as a pandas dataframe\n",
    "dfA_t0 = pd.read_csv(f\"{pathRawDataFolder}ListA_cy15Test2_CEN_onlyCorrect.csv\", sep = \",\", index_col=False, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA_t0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import list to map to (LIST B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test version, ListB contains unique names from the Epistolarium (http://ckcc.huygens.knaw.nl/epistolarium/)  (internal note: cy13)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here the second file (ListB), these are the names you want to map (find a match) to the initial list.\n",
    "# the list is imported as a pandas dataframe\n",
    "dfB_t0 = pd.read_csv(f\"{pathRawDataFolder}ListB_cy15Test2_Episto_onlyCorrect.csv\", sep = \",\", index_col=False, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB_t0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import list of correct mapped pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the local path to the test data in your own computer to where you downloaded/cloned the repository\n",
    "pathTestDataFolder = f'/Users/Melga001/stack/workspace/SKILLNET-PRODUCTION/_sharedRepositoriesGithub/mappingPersonNames/data/test/'\n",
    "\n",
    "# Import file with correct mappings only\n",
    "df3_correctMapPairs = pd.read_csv(f\"{pathTestDataFolder}correctMappedIds.csv\", sep = \",\", index_col=False, encoding= 'unicode_escape', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_correctMapPairs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare ListA and ListB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step the data is prepared for the mappings (reassigning column names and changing data types in case they were not the right ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ListA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign column names\n",
    "dfA_t0.columns = ['personIdA',\n",
    "                  'personStrIdA', #-->Delete for delivering\n",
    "                   'nameStringA',\n",
    "                   'dateBirthA', \n",
    "                   'dateDeathA', \n",
    "                   'dateFlA'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the dataframe and rename it\n",
    "dfA = dfA_t0.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datatypes and fill in empty values\n",
    "dfA_columns = dfA.columns\n",
    "for column in dfA_columns:\n",
    "    dataType = dfA.dtypes[column]\n",
    "    if dataType == np.float64:\n",
    "        dfA[column] = dfA[column].fillna(0.0)\n",
    "        dfA[column] = dfA[column].astype(int)\n",
    "    if dataType == object:\n",
    "        dfA[column] = dfA[column].fillna('null')\n",
    "        dfA[column] = dfA[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ListB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign column names\n",
    "dfB_t0.columns = [\n",
    "                   'personIdB',\n",
    "                   'personStrIdB', #--> delete for delivering\n",
    "                   'nameStringB', \n",
    "                   'dateBirthB', \n",
    "                   'dateDeathB', \n",
    "                   'dateFlB',\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the dataframe and rename it\n",
    "dfB = dfB_t0.reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datatypes and fill in empty values\n",
    "dfB_columns = dfB.columns\n",
    "for column in dfB_columns:\n",
    "    dataType = dfB.dtypes[column]\n",
    "    if dataType == np.float64:\n",
    "        dfB[column] = dfB[column].fillna(0.0)\n",
    "        dfB[column] = dfB[column].astype(int)\n",
    "    if dataType == object:\n",
    "        dfB[column] = dfB[column].fillna('null')\n",
    "        dfB[column] = dfB[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfB.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfB.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe to store the mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run mapping script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below there is the mapping script that will compare the names in listB with the names in listA checkign if the name string matches and, if so, it applies some rules to determine if the respective dates of birth/death/fl. have a logical relation. If so, a mapping candidate is added to the dataframe C.\n",
    "\n",
    "This script is also stored separately here: \n",
    "\n",
    "The counter shows:\n",
    "|percentage done|items processed/total items \\[time passed < time left, number of iterations per second\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PASTE HERE THE SCRIPT AVAILABLE IN THIS PATH: \n",
    "### {your path to repository}/mappingPersonNames/src/personMappingScript-v44-20220620.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfC.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfC.scoreCase.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare mapping output for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace the .0 in person dates and convert to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfC['dateBirthA'] = dfC['dateBirthA'].astype(str).replace('\\.0', '', regex=True)\n",
    "dfC['dateDeathA'] = dfC['dateDeathA'].astype(str).replace('\\.0', '', regex=True)\n",
    "dfC['dateFlA'] = dfC['dateFlA'].astype(str).replace('\\.0', '', regex=True)\n",
    "dfC['match_dateBirthB'] = dfC['match_dateBirthB'].astype(str).replace('\\.0', '', regex=True)\n",
    "dfC['match_dateDeathB'] = dfC['match_dateDeathB'].astype(str).replace('\\.0', '', regex=True)\n",
    "dfC['match_dateFlB'] = dfC['match_dateFlB'].astype(str).replace('\\.0', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create joined / unique names and fill the blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC['JoinedInitial'] = dfC['nameStringA'] + '^' + dfC['dateBirthA'] + '^' + dfC['dateDeathA'] + '^' + dfC['dateFlA']\n",
    "dfC['JoinedMapped'] = dfC['match_nameStringB'] + '^' + dfC['match_dateBirthB']  + '^' + dfC['match_dateDeathB'] + '^' + dfC['match_dateFlB']\n",
    "\n",
    "# Fill in blanks\n",
    "dfC['JoinedMapped'] = dfC['JoinedMapped'].fillna('notmapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfC.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the second script to detect variation in the mapped forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these joined names to strings\n",
    "dfC['JoinedInitial'] = dfC['JoinedInitial'].astype('string')\n",
    "dfC['JoinedMapped'] = dfC['JoinedMapped'].astype('string')\n",
    "\n",
    "# # convert NodegoatPersonObjectID to integer again (turns into float in previous step)\n",
    "# dfC['match_personIdB'] = dfC['match_personIdB'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j in dfC.index:\n",
    "    clear_output(wait=True)\n",
    "    rowIndex = dfC.index[j]\n",
    "    initialForm = dfC.iloc[j,13]\n",
    "    mappedForm = dfC.iloc[j,14]\n",
    "    matchScoreFinal = fuzz.ratio(initialForm, mappedForm)\n",
    "    print(\"Current progress loop1:\", np.round(j/len(dfC) *100, 2),\"%\")\n",
    "    if 0 <= matchScoreFinal <=100:\n",
    "        dfC.loc[rowIndex, 'ScoreMappedVersionsNotChangedis100'] = matchScoreFinal        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns in a way that is easier to evaluate mapping\n",
    "\n",
    "dfD = dfC[['JoinedInitial',\n",
    "        'JoinedMapped',\n",
    "        'personIdA',\n",
    "        'match_personIdB',\n",
    "        'scoreCase',\n",
    "        'scoreType',\n",
    "        'scoreNameString',\n",
    "        'ScoreMappedVersionsNotChangedis100']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfD.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfD.scoreCase.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate output of mapping script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the full candidate list from the script above\n",
    "df4_mapCandidates = dfD.reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_mapCandidates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if Ids are numbers, convert to strings\n",
    "df4_mapCandidates['match_personIdB'] = df4_mapCandidates['match_personIdB'].astype('string')\n",
    "df4_mapCandidates['match_personIdB'] = df4_mapCandidates['match_personIdB'].replace('\\.0', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_mapCandidates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the info about the file imported in step 3.3 with the correct mappings\n",
    "df3_correctMapPairs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_correctMapPairs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if Ids are numbers, convert to strings\n",
    "df3_correctMapPairs['match_personIdB'] = df3_correctMapPairs['match_personIdB'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the correct pairs column to a list\n",
    "list_correctMappingPairs = list(df3_correctMapPairs['correctMappings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column in mappings file with the pairs (to be able to compare with the correct mappings)\n",
    "df4_mapCandidates['mappingPairs'] = df4_mapCandidates['personIdA'] + ',' + df4_mapCandidates['match_personIdB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mC_all_df.mappingPairs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a mark to the full candidate list of the mappings that are correct\n",
    "df4_mapCandidates['isCorrectMapping'] = df4_mapCandidates.mappingPairs[df4_mapCandidates.mappingPairs.isin(list_correctMappingPairs)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_mapCandidates.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of mapping candidates list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct mappings in mapping candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table of CORRECT mappings that came out in the candidate mappings df\n",
    "df4_mapCandidates_CORRECT = df4_mapCandidates[df4_mapCandidates.isCorrectMapping.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_mapCandidates_CORRECT.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_mapCandidates_CORRECT.scoreCase.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_mapCandidates_CORRECT.scoreNameString.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_mapCandidates_CORRECT.scoreType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkScore2 = df4_mapCandidates_CORRECT[df4_mapCandidates_CORRECT.scoreType.str.contains('matchScore2')]\n",
    "\n",
    "checkScore2.scoreNameString.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorrect mappings in mapping candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table of INCORRECT mappings that came out in the candidate mappings df\n",
    "df4_mapCandidates_INCORRECT = df4_mapCandidates[df4_mapCandidates.isCorrectMapping.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_mapCandidates_INCORRECT.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_mapCandidates_INCORRECT.scoreCase.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_mapCandidates_INCORRECT.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkScore = df4_mapCandidates_INCORRECT[df4_mapCandidates_INCORRECT.scoreCase.str.contains('Y')]\n",
    "\n",
    "checkScore.scoreNameString.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_mapCandidates_INCORRECT.scoreType.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct mappings not detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make a list of all CORRECT mapping candidate pairs in the candidate list\n",
    "list_correctMappingPairsCandidates = list(df4_mapCandidates_CORRECT['mappingPairs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_correctMappingPairsCandidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the list of correct mapping pairs (from df3)\n",
    "len(list_correctMappingPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then compare the two lists (all correct mappings vs all correct mapping candidates) and get those from correct mappings that are not in all mappings candidates\n",
    "\n",
    "# function to get unique values\n",
    "def nonDetected(list1, list2):\n",
    "    # intilize a null list\n",
    "    not_in_list = []\n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in list2 or not\n",
    "        if x not in list2:\n",
    "            not_in_list.append(x)\n",
    "    return not_in_list\n",
    "\n",
    "\n",
    "nonDetectedCorrectMappings = nonDetected(list_correctMappingPairs, list_correctMappingPairsCandidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nonDetectedCorrectMappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonDetectedCorrectMappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to Df\n",
    "df3_correctMapPairs_nonDetected = pd.DataFrame (nonDetectedCorrectMappings, columns = ['personIdA,personIdB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_correctMapPairs_nonDetected.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split columns and assign names (https://www.kite.com/python/answers/how-to-split-a-pandas-dataframe-column-in-python)\n",
    "df3_correctMapPairs_nonDetected_t00 = df3_correctMapPairs_nonDetected['personIdA,personIdB'].str.split(\",\")\n",
    "\n",
    "df3_correctMapPairs_nonDetected_t01 = df3_correctMapPairs_nonDetected_t00.to_list()\n",
    "\n",
    "names = [\"personIdA\", \"personIdB\"]\n",
    "\n",
    "df3_correctMapPairs_nonDetected_t02 = pd.DataFrame(df3_correctMapPairs_nonDetected_t01, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_correctMapPairs_nonDetected_t02.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the df from ListA (CEN) that wasn't captured\n",
    "df1_nonDetected = df3_correctMapPairs_nonDetected_t02.merge(dfA, how = 'inner', left_on = 'personIdA', right_on = 'personIdA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_nonDetected.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the df from ListB (Epistolarium) that wasn't captured\n",
    "df2_nonDetected = df3_correctMapPairs_nonDetected_t02.merge(dfB, how = 'inner', left_on = 'personIdB', right_on = 'personIdB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_nonDetected.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dfs to get a DF with Non-detected correct mappings\n",
    "df_nonDetected = df1_nonDetected.merge(df2_nonDetected, how = 'inner', left_on = 'personIdA', right_on = 'personIdA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonDetected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if both columns from merge are the same\n",
    "check = df_nonDetected['personIdB_x'] == df_nonDetected['personIdB_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated column and rename\n",
    "df_nonDetected = df_nonDetected.drop(['personIdB_y'], axis=1).copy()\n",
    "df_nonDetected.rename(columns={\"personIdB_x\":\"personIdB\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonDetected['pairs'] = df_nonDetected['personIdA'] + ',' + df_nonDetected['personIdB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the non-detected pairs from the merge dataset are correctly in the list of non-detected mapping pairs\n",
    "\n",
    "# convert column to list\n",
    "list_correctMappingPairsNonDetected = list(df_nonDetected['pairs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if they are the same from the list of non detected mappings\n",
    "\n",
    "check2 = list_correctMappingPairsNonDetected == nonDetectedCorrectMappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine causes for not mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is it string matching score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first check if what went wrong was the string matching score\n",
    "\n",
    "for index, row in df_nonDetected.iterrows():\n",
    "    # capture variable for name in A and in B\n",
    "    nameStringA = df_nonDetected.loc[index,'nameStringA']\n",
    "    nameStringB = df_nonDetected.loc[index,'nameStringB']\n",
    "    # define scores\n",
    "    matchScore1 = fuzz.token_sort_ratio(nameStringA, nameStringB)\n",
    "    matchScore2 = fuzz.token_set_ratio(nameStringA, nameStringB)\n",
    "    df_nonDetected.loc[index,'matchScore1'] = matchScore1\n",
    "    df_nonDetected.loc[index,'matchScore2'] = matchScore2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonDetected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonDetected.matchScore1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonDetected.matchScore2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCLUSION: the cause for non-captured mappings is not the string score\n",
    "# ranges, except one, they are all above middle score value (69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is it the rules/cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonDetected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if all pairs are correctly classified in the case/score type\n",
    "\n",
    "for index, row in df_nonDetected.iterrows():\n",
    "# Capture basic standard columns for the mapping dataset B (to be mapped) as variables \n",
    "    personIdB = df_nonDetected.loc[index,'personIdB']\n",
    "    personStrIdB = df_nonDetected.loc[index,'personStrIdB']\n",
    "    nameStringB = df_nonDetected.loc[index,'nameStringB']\n",
    "    dateBirthB = df_nonDetected.loc[index,'dateBirthB']\n",
    "    dateDeathB = df_nonDetected.loc[index,'dateDeathB']\n",
    "    dateFlB = df_nonDetected.loc[index,'dateFlB']\n",
    "    # Capture basic standard columns for the mapping dataset A (to be mapped to) as variables\n",
    "    personIdA = df_nonDetected.loc[index,'personIdA']\n",
    "    personStrIdA = df_nonDetected.loc[index,'personStrIdA']\n",
    "    nameStringA = df_nonDetected.loc[index,'nameStringA']\n",
    "    dateBirthA = df_nonDetected.loc[index,'dateBirthA']\n",
    "    dateDeathA = df_nonDetected.loc[index,'dateDeathA']\n",
    "    dateFlA = df_nonDetected.loc[index,'dateFlA']\n",
    "    caseName = ''\n",
    "\n",
    "### Paste here ONLY part of the script that identifies the case\n",
    "### Script available here: ### {your path to repository}/mappingPersonNames/src/personMappingScript-v44-20220620.py\n",
    "\n",
    "    df_nonDetected.loc[index,'caseNameTest'] = caseName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonDetected.caseNameTest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkNonDetectedDf = df_nonDetected[['nameStringA', 'dateBirthA', 'dateDeathA', 'dateFlA', 'nameStringB', 'dateBirthB', 'dateDeathB', 'dateFlB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(checkNonDetectedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf = checkNonDetectedDf.reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine to which general case a person name pair corresponds\n",
    "\n",
    "for index, row in testDf.iterrows():\n",
    "# Capture basic standard columns for the mapping dataset B (to be mapped) as variables \n",
    "    # personIdB = testDf.loc[index,'personIdB']\n",
    "    # personStrIdB = testDf.loc[index,'personStrIdB']\n",
    "    nameStringB = testDf.loc[index,'nameStringB']\n",
    "    dateBirthB = testDf.loc[index,'dateBirthB']\n",
    "    dateDeathB = testDf.loc[index,'dateDeathB']\n",
    "    dateFlB = testDf.loc[index,'dateFlB']\n",
    "    # Capture basic standard columns for the mapping dataset A (to be mapped to) as variables\n",
    "    # personIdA = testDf.loc[index,'personIdA']\n",
    "    # personStrIdA = testDf.loc[index,'personStrIdA']\n",
    "    nameStringA = testDf.loc[index,'nameStringA']\n",
    "    dateBirthA = testDf.loc[index,'dateBirthA']\n",
    "    dateDeathA = testDf.loc[index,'dateDeathA']\n",
    "    dateFlA = testDf.loc[index,'dateFlA']\n",
    "    caseName = ''\n",
    "    \n",
    "    ############################## CAPTURE SCORE TYPES (NEEDS UPDATE...) #######################################\n",
    "    ############# SCORES TYPE A\n",
    "    # definition Score typeA: persons in both datasets (A and B) have complete dates of birth and death (rules = dates of birth and death are the same)\n",
    "    if ((dateBirthA != 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB != 0)) or ((dateBirthA != 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB == 0)) or ((dateBirthA != 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB != 0)) or ((dateBirthA != 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB == 0)):\n",
    "        caseName = 'A'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "    ############# SCORES TYPE B\n",
    "    # definition ScoreB: persons in either dataset A or B have complete dates of birth and death, and the mapping dataset has either of the two plus Flourished date (uses rules: either dates of birth or death are the same or with buffer, and date of Flourished is between dates of birth and/or death)\n",
    "    #### B1\n",
    "    elif ((dateBirthA != 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB != 0)) or ((dateBirthA != 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB != 0)) or ((dateBirthA != 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB != 0)) or ((dateBirthA != 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB == 0)):\n",
    "        caseName = 'B1'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "    #### B2 -> dates of death complete (applying rule for dateFl in relation to date of death of the other set)\n",
    "    elif ((dateBirthA != 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB != 0)) or ((dateBirthA != 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB == 0)):\n",
    "        caseName = 'B2'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "\n",
    "    ############# SCORES TYPE C\n",
    "    # definition ScoreC: persons in either dataset A or B have complete dates of birth and death, and the mapping dataset has either of the two but flourished date is not be present in the set with incomplete dates (rules: either dates of birth or death are the same, and Florished date is not used)\n",
    "    #### C1\n",
    "    elif ((dateBirthA != 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA != 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA != 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB != 0)) or ((dateBirthA != 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB == 0)):\n",
    "        caseName = 'C1'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "    #### C2 -> dates of death complete (applying rule for dateFl in relation to date of death of the other set)\n",
    "    elif ((dateBirthA != 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB == 0)) or ((dateBirthA != 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB == 0)):\n",
    "        caseName = 'C2'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "\n",
    "    ############# SCORES TYPE D\n",
    "    # definition ScoreD: persons in either dataset A or dataset B have either dates (of birth and/ordeath) and also both datasets have the Flourished date (uses rules: either dates of birth or death are the same (or have buffer), and date of Flourished is between dates of birth and/or death following some rules)\n",
    "    # D with date of birth\n",
    "    elif ((dateBirthA != 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB != 0)):\n",
    "        caseName = 'D'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "    # D with date of death\n",
    "    elif ((dateBirthA == 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB != 0)):\n",
    "        caseName = 'D'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "\n",
    "    ############# SCORES TYPE E\n",
    "    # definition ScoreE: none of the persons in either datasets A or B have complete dates of birth and death, one set has Flourished date the other don't (rules = either dates of birth are the same, or dates of death are the same)\n",
    "    elif ((dateBirthA != 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB == 0)) or ((dateBirthA != 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB != 0)):\n",
    "        caseName = 'E'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "\n",
    "    ############# SCORES TYPE F\n",
    "    # definition ScoreF: none of the persons in datasets A or B have complete dates of birth and death, they don't have Flourished date either (rules = either dates of birth are the same, or dates of death are the same, or with buffer)\n",
    "    elif ((dateBirthA != 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB == 0)):\n",
    "        caseName = 'F'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "\n",
    "    ############# SCORES TYPE G\n",
    "    # definition ScoreG: persons in one of the datasets have complete dates of birth and death (Flourished date is optional) and persons to map have only Flourished date (rules: one of the persons has complete dates of birth and death, the other person has only Flourished date, which is between dates of birth and/or death following some rules)\n",
    "    # both datasets have dfl\n",
    "    elif ((dateBirthA != 0 and dateDeathA != 0 and dateFlA !=0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA !=0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB != 0)):\n",
    "        caseName = 'G1'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "    # one of the datasets doesn't have dfl\n",
    "    elif ((dateBirthA != 0 and dateDeathA != 0 and dateFlA ==0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB != 0)):\n",
    "        caseName = 'G2'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "    elif ((dateBirthA == 0 and dateDeathA == 0 and dateFlA !=0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB == 0)):\n",
    "        caseName = 'G2'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "    \n",
    "\n",
    "\n",
    "    ############# SCORES TYPE H\n",
    "    # definition ScoreH: persons in both datasets have incomplete dates of birth and death (either of the two in contrary way), but Flourished date is there\n",
    "    elif ((dateBirthA != 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB != 0)):    \n",
    "        caseName = 'H'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "\n",
    "    ############# SCORES TYPE I \n",
    "    # definition Score I: persons in both datasets have incomplete dates of birth and death (either of the two in contrary way), and Flourished date is only in one of the sets\n",
    "    elif ((dateBirthA != 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB != 0)) or ((dateBirthA != 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB != 0)):\n",
    "        caseName = 'I'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "\n",
    "    ############# SCORES TYPE J\n",
    "    # definition ScoreJ: persons in both datasets have incomplete dates of birth and death (either of the two) in the opposite way, and none has Flourished date\n",
    "    elif ((dateBirthA != 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB == 0)):\n",
    "        caseName = 'J'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "\n",
    "    ############# SCORES TYPE K\n",
    "    #definition ScoreK: persons in one dataset have incomplete dates of birth and death (either of the two) plus Flourished date, and persons in the other dataset have none of the two, only Flourished date\n",
    "    elif ((dateBirthA != 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB != 0)):\n",
    "        caseName = 'K'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "\n",
    "    ############# SCORES TYPE L\n",
    "    # definition ScoreL: persons in one dataset have incomplete dates of birth and death (either of the two) and no Flourished date, persons in the other dataset have no date of birth nor death, but do have Flourished date\n",
    "    elif ((dateBirthA != 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB == 0)):  \n",
    "        caseName = 'L'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "\n",
    "    # ############# SCORES TYPE M\n",
    "    # definition ScoreM: persons in both datasets have only date of Flourished\n",
    "    elif (dateBirthA == 0 and dateBirthA == 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB != 0):\n",
    "        caseName = 'M'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "                \n",
    "\n",
    "    # SCORES TYPE X\n",
    "    # definition ScoreX: persons in one dataset have both dates, and in the other dataset no dates at all\n",
    "    elif ((dateBirthA != 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA != 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB != 0 and dateFlB == 0)):\n",
    "        caseName = 'X'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "                                \n",
    "\n",
    "    ############# SCORES TYPE Y\n",
    "    # definition ScoreY: persons in one dataset have either date, and in the other dataset no dates at all\n",
    "    elif ((dateBirthA != 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA != 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA != 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA != 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB != 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB != 0 and dateDeathB == 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB != 0 and dateFlB == 0)) or ((dateBirthA == 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB != 0)):\n",
    "        caseName = 'Y'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n",
    "\n",
    "    ############# SCORES TYPE Z\n",
    "    # definition ScoreZ: this group includes persons with no dates at all in both datasets, scores rely on string matching only (no other rules)\n",
    "    elif (dateBirthA == 0 and dateDeathA == 0 and dateFlA == 0) and (dateBirthB == 0 and dateDeathB == 0 and dateFlB == 0):\n",
    "        caseName = 'Z'\n",
    "        caseNameAdd = testDf.loc[index, 'caseName'] = caseName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testDf.iloc[10,1] == testDf.iloc[10,5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
